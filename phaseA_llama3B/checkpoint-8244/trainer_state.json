{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999393535083996,
  "eval_steps": 500,
  "global_step": 8244,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012129298320092182,
      "grad_norm": 0.7550684213638306,
      "learning_rate": 4.842615012106538e-05,
      "loss": 4.5133,
      "step": 100
    },
    {
      "epoch": 0.024258596640184364,
      "grad_norm": 0.8447781205177307,
      "learning_rate": 9.685230024213076e-05,
      "loss": 0.9689,
      "step": 200
    },
    {
      "epoch": 0.03638789496027655,
      "grad_norm": 0.8878744840621948,
      "learning_rate": 0.00014527845036319613,
      "loss": 0.7556,
      "step": 300
    },
    {
      "epoch": 0.04851719328036873,
      "grad_norm": 0.706315815448761,
      "learning_rate": 0.00019370460048426152,
      "loss": 0.6506,
      "step": 400
    },
    {
      "epoch": 0.060646491600460914,
      "grad_norm": 0.7641805410385132,
      "learning_rate": 0.00019993909825732396,
      "loss": 0.6401,
      "step": 500
    },
    {
      "epoch": 0.0727757899205531,
      "grad_norm": 0.684843897819519,
      "learning_rate": 0.00019971873556283516,
      "loss": 0.6131,
      "step": 600
    },
    {
      "epoch": 0.08490508824064529,
      "grad_norm": 0.7374492287635803,
      "learning_rate": 0.00019933790657776387,
      "loss": 0.6083,
      "step": 700
    },
    {
      "epoch": 0.09703438656073746,
      "grad_norm": 0.8547175526618958,
      "learning_rate": 0.00019879722412791695,
      "loss": 0.6069,
      "step": 800
    },
    {
      "epoch": 0.10916368488082964,
      "grad_norm": 0.6386758685112,
      "learning_rate": 0.0001980975582735355,
      "loss": 0.5991,
      "step": 900
    },
    {
      "epoch": 0.12129298320092183,
      "grad_norm": 0.696323573589325,
      "learning_rate": 0.00019724003490920368,
      "loss": 0.5866,
      "step": 1000
    },
    {
      "epoch": 0.133422281521014,
      "grad_norm": 0.5638753771781921,
      "learning_rate": 0.00019622603395207116,
      "loss": 0.5843,
      "step": 1100
    },
    {
      "epoch": 0.1455515798411062,
      "grad_norm": 0.6871115565299988,
      "learning_rate": 0.00019505718712130622,
      "loss": 0.5862,
      "step": 1200
    },
    {
      "epoch": 0.15768087816119838,
      "grad_norm": 0.6178405284881592,
      "learning_rate": 0.00019373537531235067,
      "loss": 0.5842,
      "step": 1300
    },
    {
      "epoch": 0.16981017648129057,
      "grad_norm": 0.5872987508773804,
      "learning_rate": 0.00019226272557020395,
      "loss": 0.5719,
      "step": 1400
    },
    {
      "epoch": 0.18193947480138273,
      "grad_norm": 0.6926041841506958,
      "learning_rate": 0.00019064160766660575,
      "loss": 0.5619,
      "step": 1500
    },
    {
      "epoch": 0.1940687731214749,
      "grad_norm": 0.5491539239883423,
      "learning_rate": 0.0001888746302866253,
      "loss": 0.5634,
      "step": 1600
    },
    {
      "epoch": 0.2061980714415671,
      "grad_norm": 0.6465951800346375,
      "learning_rate": 0.0001869646368307942,
      "loss": 0.5651,
      "step": 1700
    },
    {
      "epoch": 0.21832736976165928,
      "grad_norm": 0.5788040161132812,
      "learning_rate": 0.00018491470083953755,
      "loss": 0.5512,
      "step": 1800
    },
    {
      "epoch": 0.23045666808175147,
      "grad_norm": 0.5855095982551575,
      "learning_rate": 0.00018272812104726664,
      "loss": 0.5515,
      "step": 1900
    },
    {
      "epoch": 0.24258596640184366,
      "grad_norm": 0.6126129031181335,
      "learning_rate": 0.00018040841607409175,
      "loss": 0.5491,
      "step": 2000
    },
    {
      "epoch": 0.25471526472193584,
      "grad_norm": 0.5798547267913818,
      "learning_rate": 0.00017795931876369764,
      "loss": 0.5564,
      "step": 2100
    },
    {
      "epoch": 0.266844563042028,
      "grad_norm": 0.6210729479789734,
      "learning_rate": 0.0001753847701764924,
      "loss": 0.5472,
      "step": 2200
    },
    {
      "epoch": 0.2789738613621202,
      "grad_norm": 0.6276574730873108,
      "learning_rate": 0.0001726889132476966,
      "loss": 0.5441,
      "step": 2300
    },
    {
      "epoch": 0.2911031596822124,
      "grad_norm": 0.7097540497779846,
      "learning_rate": 0.00016987608612057745,
      "loss": 0.5437,
      "step": 2400
    },
    {
      "epoch": 0.3032324580023046,
      "grad_norm": 0.6457000970840454,
      "learning_rate": 0.00016695081516555674,
      "loss": 0.5381,
      "step": 2500
    },
    {
      "epoch": 0.31536175632239677,
      "grad_norm": 0.6954137086868286,
      "learning_rate": 0.0001639178076964251,
      "loss": 0.5377,
      "step": 2600
    },
    {
      "epoch": 0.32749105464248895,
      "grad_norm": 0.5773603916168213,
      "learning_rate": 0.00016078194439538463,
      "loss": 0.5343,
      "step": 2700
    },
    {
      "epoch": 0.33962035296258114,
      "grad_norm": 0.5661855936050415,
      "learning_rate": 0.0001575482714591089,
      "loss": 0.533,
      "step": 2800
    },
    {
      "epoch": 0.35174965128267327,
      "grad_norm": 0.5984250903129578,
      "learning_rate": 0.0001542219924784589,
      "loss": 0.531,
      "step": 2900
    },
    {
      "epoch": 0.36387894960276546,
      "grad_norm": 0.5864564180374146,
      "learning_rate": 0.00015080846006492192,
      "loss": 0.5347,
      "step": 3000
    },
    {
      "epoch": 0.37600824792285764,
      "grad_norm": 0.631274938583374,
      "learning_rate": 0.000147313167237248,
      "loss": 0.5306,
      "step": 3100
    },
    {
      "epoch": 0.3881375462429498,
      "grad_norm": 0.7544569969177246,
      "learning_rate": 0.00014374173858214487,
      "loss": 0.5277,
      "step": 3200
    },
    {
      "epoch": 0.400266844563042,
      "grad_norm": 1.2276698350906372,
      "learning_rate": 0.00014009992120325487,
      "loss": 0.5251,
      "step": 3300
    },
    {
      "epoch": 0.4123961428831342,
      "grad_norm": 0.6111190915107727,
      "learning_rate": 0.0001363935754729792,
      "loss": 0.5228,
      "step": 3400
    },
    {
      "epoch": 0.4245254412032264,
      "grad_norm": 0.6058210730552673,
      "learning_rate": 0.00013262866560203102,
      "loss": 0.5177,
      "step": 3500
    },
    {
      "epoch": 0.43665473952331857,
      "grad_norm": 0.6695749759674072,
      "learning_rate": 0.00012881125004189352,
      "loss": 0.5165,
      "step": 3600
    },
    {
      "epoch": 0.44878403784341075,
      "grad_norm": 0.6535137295722961,
      "learning_rate": 0.00012494747173562643,
      "loss": 0.513,
      "step": 3700
    },
    {
      "epoch": 0.46091333616350294,
      "grad_norm": 0.7823132872581482,
      "learning_rate": 0.00012104354823270962,
      "loss": 0.5109,
      "step": 3800
    },
    {
      "epoch": 0.4730426344835951,
      "grad_norm": 0.6677023768424988,
      "learning_rate": 0.0001171057616838312,
      "loss": 0.5087,
      "step": 3900
    },
    {
      "epoch": 0.4851719328036873,
      "grad_norm": 0.581587553024292,
      "learning_rate": 0.00011314044873171974,
      "loss": 0.5122,
      "step": 4000
    },
    {
      "epoch": 0.4973012311237795,
      "grad_norm": 0.7046986818313599,
      "learning_rate": 0.00010915399031428858,
      "loss": 0.5057,
      "step": 4100
    },
    {
      "epoch": 0.5094305294438717,
      "grad_norm": 0.6790688633918762,
      "learning_rate": 0.00010515280139650088,
      "loss": 0.5038,
      "step": 4200
    },
    {
      "epoch": 0.5215598277639638,
      "grad_norm": 0.7459737658500671,
      "learning_rate": 0.00010114332064747869,
      "loss": 0.5016,
      "step": 4300
    },
    {
      "epoch": 0.533689126084056,
      "grad_norm": 0.7070573568344116,
      "learning_rate": 9.713200007946748e-05,
      "loss": 0.4982,
      "step": 4400
    },
    {
      "epoch": 0.5458184244041482,
      "grad_norm": 0.6704773902893066,
      "learning_rate": 9.312529466532925e-05,
      "loss": 0.4957,
      "step": 4500
    },
    {
      "epoch": 0.5579477227242404,
      "grad_norm": 0.7105139493942261,
      "learning_rate": 8.912965195127113e-05,
      "loss": 0.5013,
      "step": 4600
    },
    {
      "epoch": 0.5700770210443326,
      "grad_norm": 0.6909511089324951,
      "learning_rate": 8.515150168152527e-05,
      "loss": 0.502,
      "step": 4700
    },
    {
      "epoch": 0.5822063193644248,
      "grad_norm": 0.7475619912147522,
      "learning_rate": 8.11972454516751e-05,
      "loss": 0.5011,
      "step": 4800
    },
    {
      "epoch": 0.5943356176845169,
      "grad_norm": 0.6937381029129028,
      "learning_rate": 7.72732464072783e-05,
      "loss": 0.4992,
      "step": 4900
    },
    {
      "epoch": 0.6064649160046092,
      "grad_norm": 0.723712682723999,
      "learning_rate": 7.338581900436318e-05,
      "loss": 0.4952,
      "step": 5000
    },
    {
      "epoch": 0.6185942143247013,
      "grad_norm": 0.7307647466659546,
      "learning_rate": 6.95412188482754e-05,
      "loss": 0.4881,
      "step": 5100
    },
    {
      "epoch": 0.6307235126447935,
      "grad_norm": 0.8213850855827332,
      "learning_rate": 6.574563262722695e-05,
      "loss": 0.4926,
      "step": 5200
    },
    {
      "epoch": 0.6428528109648857,
      "grad_norm": 0.6926903128623962,
      "learning_rate": 6.200516815674558e-05,
      "loss": 0.4921,
      "step": 5300
    },
    {
      "epoch": 0.6549821092849779,
      "grad_norm": 0.7952414751052856,
      "learning_rate": 5.832584455104537e-05,
      "loss": 0.49,
      "step": 5400
    },
    {
      "epoch": 0.66711140760507,
      "grad_norm": 0.8531940579414368,
      "learning_rate": 5.4713582537134364e-05,
      "loss": 0.4929,
      "step": 5500
    },
    {
      "epoch": 0.6792407059251623,
      "grad_norm": 0.7177296876907349,
      "learning_rate": 5.117419492724603e-05,
      "loss": 0.49,
      "step": 5600
    },
    {
      "epoch": 0.6913700042452544,
      "grad_norm": 0.7529974579811096,
      "learning_rate": 4.7713377264925804e-05,
      "loss": 0.4886,
      "step": 5700
    },
    {
      "epoch": 0.7034993025653465,
      "grad_norm": 0.8603448867797852,
      "learning_rate": 4.433669865982514e-05,
      "loss": 0.489,
      "step": 5800
    },
    {
      "epoch": 0.7156286008854388,
      "grad_norm": 0.7802339792251587,
      "learning_rate": 4.1049592825951665e-05,
      "loss": 0.4813,
      "step": 5900
    },
    {
      "epoch": 0.7277578992055309,
      "grad_norm": 0.8590427041053772,
      "learning_rate": 3.785734933779642e-05,
      "loss": 0.4942,
      "step": 6000
    },
    {
      "epoch": 0.7398871975256232,
      "grad_norm": 0.7324844002723694,
      "learning_rate": 3.4765105118408935e-05,
      "loss": 0.4862,
      "step": 6100
    },
    {
      "epoch": 0.7520164958457153,
      "grad_norm": 0.7760002613067627,
      "learning_rate": 3.1777836173117195e-05,
      "loss": 0.4862,
      "step": 6200
    },
    {
      "epoch": 0.7641457941658075,
      "grad_norm": 0.815187931060791,
      "learning_rate": 2.8900349582194675e-05,
      "loss": 0.4789,
      "step": 6300
    },
    {
      "epoch": 0.7762750924858997,
      "grad_norm": 0.792455792427063,
      "learning_rate": 2.6137275765359824e-05,
      "loss": 0.4794,
      "step": 6400
    },
    {
      "epoch": 0.7884043908059919,
      "grad_norm": 0.8318149447441101,
      "learning_rate": 2.3493061030555576e-05,
      "loss": 0.4816,
      "step": 6500
    },
    {
      "epoch": 0.800533689126084,
      "grad_norm": 0.794499397277832,
      "learning_rate": 2.097196041899967e-05,
      "loss": 0.4819,
      "step": 6600
    },
    {
      "epoch": 0.8126629874461763,
      "grad_norm": 0.823218047618866,
      "learning_rate": 1.857803085801908e-05,
      "loss": 0.4853,
      "step": 6700
    },
    {
      "epoch": 0.8247922857662684,
      "grad_norm": 0.8574874997138977,
      "learning_rate": 1.6315124632687416e-05,
      "loss": 0.4849,
      "step": 6800
    },
    {
      "epoch": 0.8369215840863606,
      "grad_norm": 0.9335762858390808,
      "learning_rate": 1.418688318677015e-05,
      "loss": 0.4805,
      "step": 6900
    },
    {
      "epoch": 0.8490508824064528,
      "grad_norm": 0.795157790184021,
      "learning_rate": 1.2196731262953431e-05,
      "loss": 0.4793,
      "step": 7000
    },
    {
      "epoch": 0.861180180726545,
      "grad_norm": 0.8793413043022156,
      "learning_rate": 1.034787139178588e-05,
      "loss": 0.4777,
      "step": 7100
    },
    {
      "epoch": 0.8733094790466371,
      "grad_norm": 0.871553361415863,
      "learning_rate": 8.643278738201732e-06,
      "loss": 0.4762,
      "step": 7200
    },
    {
      "epoch": 0.8854387773667294,
      "grad_norm": 0.879496693611145,
      "learning_rate": 7.0856963139182e-06,
      "loss": 0.4766,
      "step": 7300
    },
    {
      "epoch": 0.8975680756868215,
      "grad_norm": 0.863518238067627,
      "learning_rate": 5.677630563411263e-06,
      "loss": 0.4819,
      "step": 7400
    },
    {
      "epoch": 0.9096973740069138,
      "grad_norm": 0.7745221853256226,
      "learning_rate": 4.421347330572767e-06,
      "loss": 0.4776,
      "step": 7500
    },
    {
      "epoch": 0.9218266723270059,
      "grad_norm": 0.8898761868476868,
      "learning_rate": 3.3188682125394833e-06,
      "loss": 0.4817,
      "step": 7600
    },
    {
      "epoch": 0.933955970647098,
      "grad_norm": 0.8132758736610413,
      "learning_rate": 2.371967306561218e-06,
      "loss": 0.4817,
      "step": 7700
    },
    {
      "epoch": 0.9460852689671903,
      "grad_norm": 0.7544003129005432,
      "learning_rate": 1.5821683551430433e-06,
      "loss": 0.4765,
      "step": 7800
    },
    {
      "epoch": 0.9582145672872824,
      "grad_norm": 0.7473258972167969,
      "learning_rate": 9.507422940557176e-07,
      "loss": 0.4716,
      "step": 7900
    },
    {
      "epoch": 0.9703438656073746,
      "grad_norm": 0.8522962331771851,
      "learning_rate": 4.787052071597909e-07,
      "loss": 0.4811,
      "step": 8000
    },
    {
      "epoch": 0.9824731639274668,
      "grad_norm": 1.0160953998565674,
      "learning_rate": 1.6681669133465917e-07,
      "loss": 0.4702,
      "step": 8100
    },
    {
      "epoch": 0.994602462247559,
      "grad_norm": 0.9232506155967712,
      "learning_rate": 1.557863414365368e-08,
      "loss": 0.4757,
      "step": 8200
    }
  ],
  "logging_steps": 100,
  "max_steps": 8244,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.209378865847009e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
