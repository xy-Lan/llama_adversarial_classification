{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999393535083996,
  "eval_steps": 500,
  "global_step": 8244,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012129298320092182,
      "grad_norm": 3.7590291500091553,
      "learning_rate": 4.842615012106538e-05,
      "loss": 5.1163,
      "step": 100
    },
    {
      "epoch": 0.024258596640184364,
      "grad_norm": 4.140365123748779,
      "learning_rate": 9.685230024213076e-05,
      "loss": 1.061,
      "step": 200
    },
    {
      "epoch": 0.03638789496027655,
      "grad_norm": 1.0477741956710815,
      "learning_rate": 0.00014527845036319613,
      "loss": 1.0016,
      "step": 300
    },
    {
      "epoch": 0.04851719328036873,
      "grad_norm": 1.2048921585083008,
      "learning_rate": 0.00019370460048426152,
      "loss": 0.9828,
      "step": 400
    },
    {
      "epoch": 0.060646491600460914,
      "grad_norm": 1.5843557119369507,
      "learning_rate": 0.00019993909825732396,
      "loss": 0.9315,
      "step": 500
    },
    {
      "epoch": 0.0727757899205531,
      "grad_norm": 1.0146297216415405,
      "learning_rate": 0.00019971873556283516,
      "loss": 0.6804,
      "step": 600
    },
    {
      "epoch": 0.08490508824064529,
      "grad_norm": 1.2365612983703613,
      "learning_rate": 0.00019933790657776387,
      "loss": 0.6637,
      "step": 700
    },
    {
      "epoch": 0.09703438656073746,
      "grad_norm": 1.2511953115463257,
      "learning_rate": 0.00019879722412791695,
      "loss": 0.661,
      "step": 800
    },
    {
      "epoch": 0.10916368488082964,
      "grad_norm": 0.9923930764198303,
      "learning_rate": 0.0001980975582735355,
      "loss": 0.6506,
      "step": 900
    },
    {
      "epoch": 0.12129298320092183,
      "grad_norm": 1.0172760486602783,
      "learning_rate": 0.00019724003490920368,
      "loss": 0.635,
      "step": 1000
    },
    {
      "epoch": 0.133422281521014,
      "grad_norm": 0.8156437277793884,
      "learning_rate": 0.00019622603395207116,
      "loss": 0.6329,
      "step": 1100
    },
    {
      "epoch": 0.1455515798411062,
      "grad_norm": 0.9531911015510559,
      "learning_rate": 0.00019505718712130622,
      "loss": 0.6376,
      "step": 1200
    },
    {
      "epoch": 0.15768087816119838,
      "grad_norm": 0.9369115829467773,
      "learning_rate": 0.00019373537531235067,
      "loss": 0.6346,
      "step": 1300
    },
    {
      "epoch": 0.16981017648129057,
      "grad_norm": 0.846359133720398,
      "learning_rate": 0.00019226272557020395,
      "loss": 0.6211,
      "step": 1400
    },
    {
      "epoch": 0.18193947480138273,
      "grad_norm": 0.9444471597671509,
      "learning_rate": 0.00019064160766660575,
      "loss": 0.6078,
      "step": 1500
    },
    {
      "epoch": 0.1940687731214749,
      "grad_norm": 0.8259865045547485,
      "learning_rate": 0.0001888746302866253,
      "loss": 0.6117,
      "step": 1600
    },
    {
      "epoch": 0.2061980714415671,
      "grad_norm": 0.8166983127593994,
      "learning_rate": 0.0001869646368307942,
      "loss": 0.6108,
      "step": 1700
    },
    {
      "epoch": 0.21832736976165928,
      "grad_norm": 0.8481353521347046,
      "learning_rate": 0.00018491470083953755,
      "loss": 0.596,
      "step": 1800
    },
    {
      "epoch": 0.23045666808175147,
      "grad_norm": 0.8720138669013977,
      "learning_rate": 0.00018272812104726664,
      "loss": 0.5977,
      "step": 1900
    },
    {
      "epoch": 0.24258596640184366,
      "grad_norm": 0.9306630492210388,
      "learning_rate": 0.00018040841607409175,
      "loss": 0.5957,
      "step": 2000
    },
    {
      "epoch": 0.25471526472193584,
      "grad_norm": 0.7845724821090698,
      "learning_rate": 0.00017795931876369764,
      "loss": 0.6045,
      "step": 2100
    },
    {
      "epoch": 0.266844563042028,
      "grad_norm": 0.8935300707817078,
      "learning_rate": 0.0001753847701764924,
      "loss": 0.5925,
      "step": 2200
    },
    {
      "epoch": 0.2789738613621202,
      "grad_norm": 1.0089532136917114,
      "learning_rate": 0.0001726889132476966,
      "loss": 0.5912,
      "step": 2300
    },
    {
      "epoch": 0.2911031596822124,
      "grad_norm": 0.8396617770195007,
      "learning_rate": 0.00016987608612057745,
      "loss": 0.5925,
      "step": 2400
    },
    {
      "epoch": 0.3032324580023046,
      "grad_norm": 0.8516388535499573,
      "learning_rate": 0.00016695081516555674,
      "loss": 0.5857,
      "step": 2500
    },
    {
      "epoch": 0.31536175632239677,
      "grad_norm": 0.8298287391662598,
      "learning_rate": 0.0001639178076964251,
      "loss": 0.5862,
      "step": 2600
    },
    {
      "epoch": 0.32749105464248895,
      "grad_norm": 0.8015648722648621,
      "learning_rate": 0.00016078194439538463,
      "loss": 0.5802,
      "step": 2700
    },
    {
      "epoch": 0.33962035296258114,
      "grad_norm": 0.7784186005592346,
      "learning_rate": 0.0001575482714591089,
      "loss": 0.5847,
      "step": 2800
    },
    {
      "epoch": 0.35174965128267327,
      "grad_norm": 0.8541566729545593,
      "learning_rate": 0.0001542219924784589,
      "loss": 0.5769,
      "step": 2900
    },
    {
      "epoch": 0.36387894960276546,
      "grad_norm": 0.7529846429824829,
      "learning_rate": 0.00015080846006492192,
      "loss": 0.5849,
      "step": 3000
    },
    {
      "epoch": 0.37600824792285764,
      "grad_norm": 0.8676475286483765,
      "learning_rate": 0.000147313167237248,
      "loss": 0.579,
      "step": 3100
    },
    {
      "epoch": 0.3881375462429498,
      "grad_norm": 0.9130778908729553,
      "learning_rate": 0.00014374173858214487,
      "loss": 0.5755,
      "step": 3200
    },
    {
      "epoch": 0.400266844563042,
      "grad_norm": 0.9372310042381287,
      "learning_rate": 0.00014009992120325487,
      "loss": 0.574,
      "step": 3300
    },
    {
      "epoch": 0.4123961428831342,
      "grad_norm": 0.9485562443733215,
      "learning_rate": 0.0001363935754729792,
      "loss": 0.5716,
      "step": 3400
    },
    {
      "epoch": 0.4245254412032264,
      "grad_norm": 0.8241159319877625,
      "learning_rate": 0.00013262866560203102,
      "loss": 0.5663,
      "step": 3500
    },
    {
      "epoch": 0.43665473952331857,
      "grad_norm": 0.9513602256774902,
      "learning_rate": 0.00012881125004189352,
      "loss": 0.5661,
      "step": 3600
    },
    {
      "epoch": 0.44878403784341075,
      "grad_norm": 0.8591054081916809,
      "learning_rate": 0.00012494747173562643,
      "loss": 0.567,
      "step": 3700
    },
    {
      "epoch": 0.46091333616350294,
      "grad_norm": 1.1662242412567139,
      "learning_rate": 0.00012104354823270962,
      "loss": 0.5598,
      "step": 3800
    },
    {
      "epoch": 0.4730426344835951,
      "grad_norm": 0.8622047901153564,
      "learning_rate": 0.0001171057616838312,
      "loss": 0.5595,
      "step": 3900
    },
    {
      "epoch": 0.4851719328036873,
      "grad_norm": 0.8199980854988098,
      "learning_rate": 0.00011314044873171974,
      "loss": 0.5608,
      "step": 4000
    },
    {
      "epoch": 0.4973012311237795,
      "grad_norm": 0.8556929230690002,
      "learning_rate": 0.00010915399031428858,
      "loss": 0.5569,
      "step": 4100
    },
    {
      "epoch": 0.5094305294438717,
      "grad_norm": 0.8663672208786011,
      "learning_rate": 0.00010515280139650088,
      "loss": 0.5561,
      "step": 4200
    },
    {
      "epoch": 0.5215598277639638,
      "grad_norm": 0.9341451525688171,
      "learning_rate": 0.00010114332064747869,
      "loss": 0.5516,
      "step": 4300
    },
    {
      "epoch": 0.533689126084056,
      "grad_norm": 0.8918956518173218,
      "learning_rate": 9.713200007946748e-05,
      "loss": 0.5512,
      "step": 4400
    },
    {
      "epoch": 0.5458184244041482,
      "grad_norm": 0.8664429187774658,
      "learning_rate": 9.312529466532925e-05,
      "loss": 0.5484,
      "step": 4500
    },
    {
      "epoch": 0.5579477227242404,
      "grad_norm": 0.8630310893058777,
      "learning_rate": 8.912965195127113e-05,
      "loss": 0.5554,
      "step": 4600
    },
    {
      "epoch": 0.5700770210443326,
      "grad_norm": 0.8850580453872681,
      "learning_rate": 8.515150168152527e-05,
      "loss": 0.5566,
      "step": 4700
    },
    {
      "epoch": 0.5822063193644248,
      "grad_norm": 0.9061933159828186,
      "learning_rate": 8.11972454516751e-05,
      "loss": 0.5556,
      "step": 4800
    },
    {
      "epoch": 0.5943356176845169,
      "grad_norm": 0.8935261964797974,
      "learning_rate": 7.72732464072783e-05,
      "loss": 0.5533,
      "step": 4900
    },
    {
      "epoch": 0.6064649160046092,
      "grad_norm": 0.8677241206169128,
      "learning_rate": 7.338581900436318e-05,
      "loss": 0.5482,
      "step": 5000
    },
    {
      "epoch": 0.6185942143247013,
      "grad_norm": 0.9451634883880615,
      "learning_rate": 6.95412188482754e-05,
      "loss": 0.5429,
      "step": 5100
    },
    {
      "epoch": 0.6307235126447935,
      "grad_norm": 1.1482442617416382,
      "learning_rate": 6.574563262722695e-05,
      "loss": 0.5458,
      "step": 5200
    },
    {
      "epoch": 0.6428528109648857,
      "grad_norm": 0.9084904193878174,
      "learning_rate": 6.200516815674558e-05,
      "loss": 0.5478,
      "step": 5300
    },
    {
      "epoch": 0.6549821092849779,
      "grad_norm": 0.8585971593856812,
      "learning_rate": 5.832584455104537e-05,
      "loss": 0.5459,
      "step": 5400
    },
    {
      "epoch": 0.66711140760507,
      "grad_norm": 1.0697948932647705,
      "learning_rate": 5.4713582537134364e-05,
      "loss": 0.5498,
      "step": 5500
    },
    {
      "epoch": 0.6792407059251623,
      "grad_norm": 0.8697479963302612,
      "learning_rate": 5.117419492724603e-05,
      "loss": 0.5491,
      "step": 5600
    },
    {
      "epoch": 0.6913700042452544,
      "grad_norm": 1.001725673675537,
      "learning_rate": 4.7713377264925804e-05,
      "loss": 0.5453,
      "step": 5700
    },
    {
      "epoch": 0.7034993025653465,
      "grad_norm": 0.962509274482727,
      "learning_rate": 4.433669865982514e-05,
      "loss": 0.5477,
      "step": 5800
    },
    {
      "epoch": 0.7156286008854388,
      "grad_norm": 0.9970455169677734,
      "learning_rate": 4.1049592825951665e-05,
      "loss": 0.539,
      "step": 5900
    },
    {
      "epoch": 0.7277578992055309,
      "grad_norm": 1.0051440000534058,
      "learning_rate": 3.785734933779642e-05,
      "loss": 0.5523,
      "step": 6000
    },
    {
      "epoch": 0.7398871975256232,
      "grad_norm": 0.9614179730415344,
      "learning_rate": 3.4765105118408935e-05,
      "loss": 0.547,
      "step": 6100
    },
    {
      "epoch": 0.7520164958457153,
      "grad_norm": 1.0053560733795166,
      "learning_rate": 3.1777836173117195e-05,
      "loss": 0.5437,
      "step": 6200
    },
    {
      "epoch": 0.7641457941658075,
      "grad_norm": 1.0098373889923096,
      "learning_rate": 2.8900349582194675e-05,
      "loss": 0.5361,
      "step": 6300
    },
    {
      "epoch": 0.7762750924858997,
      "grad_norm": 0.967681348323822,
      "learning_rate": 2.6137275765359824e-05,
      "loss": 0.5337,
      "step": 6400
    },
    {
      "epoch": 0.7884043908059919,
      "grad_norm": 0.9333932399749756,
      "learning_rate": 2.3493061030555576e-05,
      "loss": 0.5395,
      "step": 6500
    },
    {
      "epoch": 0.800533689126084,
      "grad_norm": 1.002768874168396,
      "learning_rate": 2.097196041899967e-05,
      "loss": 0.5435,
      "step": 6600
    },
    {
      "epoch": 0.8126629874461763,
      "grad_norm": 1.040846824645996,
      "learning_rate": 1.857803085801908e-05,
      "loss": 0.5433,
      "step": 6700
    },
    {
      "epoch": 0.8247922857662684,
      "grad_norm": 0.9147815704345703,
      "learning_rate": 1.6315124632687416e-05,
      "loss": 0.542,
      "step": 6800
    },
    {
      "epoch": 0.8369215840863606,
      "grad_norm": 1.0407826900482178,
      "learning_rate": 1.418688318677015e-05,
      "loss": 0.5385,
      "step": 6900
    },
    {
      "epoch": 0.8490508824064528,
      "grad_norm": 0.9157319664955139,
      "learning_rate": 1.2196731262953431e-05,
      "loss": 0.5369,
      "step": 7000
    },
    {
      "epoch": 0.861180180726545,
      "grad_norm": 0.9952035546302795,
      "learning_rate": 1.034787139178588e-05,
      "loss": 0.5357,
      "step": 7100
    },
    {
      "epoch": 0.8733094790466371,
      "grad_norm": 1.1206852197647095,
      "learning_rate": 8.643278738201732e-06,
      "loss": 0.5362,
      "step": 7200
    },
    {
      "epoch": 0.8854387773667294,
      "grad_norm": 1.072749137878418,
      "learning_rate": 7.0856963139182e-06,
      "loss": 0.5336,
      "step": 7300
    },
    {
      "epoch": 0.8975680756868215,
      "grad_norm": 0.960442304611206,
      "learning_rate": 5.677630563411263e-06,
      "loss": 0.5405,
      "step": 7400
    },
    {
      "epoch": 0.9096973740069138,
      "grad_norm": 0.9136161804199219,
      "learning_rate": 4.421347330572767e-06,
      "loss": 0.5362,
      "step": 7500
    },
    {
      "epoch": 0.9218266723270059,
      "grad_norm": 1.0431110858917236,
      "learning_rate": 3.3188682125394833e-06,
      "loss": 0.5399,
      "step": 7600
    },
    {
      "epoch": 0.933955970647098,
      "grad_norm": 1.0178412199020386,
      "learning_rate": 2.371967306561218e-06,
      "loss": 0.5388,
      "step": 7700
    },
    {
      "epoch": 0.9460852689671903,
      "grad_norm": 0.951195240020752,
      "learning_rate": 1.5821683551430433e-06,
      "loss": 0.5394,
      "step": 7800
    },
    {
      "epoch": 0.9582145672872824,
      "grad_norm": 0.9814656972885132,
      "learning_rate": 9.507422940557176e-07,
      "loss": 0.5292,
      "step": 7900
    },
    {
      "epoch": 0.9703438656073746,
      "grad_norm": 1.0194529294967651,
      "learning_rate": 4.787052071597909e-07,
      "loss": 0.5435,
      "step": 8000
    },
    {
      "epoch": 0.9824731639274668,
      "grad_norm": 1.2360461950302124,
      "learning_rate": 1.6681669133465917e-07,
      "loss": 0.5291,
      "step": 8100
    },
    {
      "epoch": 0.994602462247559,
      "grad_norm": 1.035259485244751,
      "learning_rate": 1.557863414365368e-08,
      "loss": 0.535,
      "step": 8200
    }
  ],
  "logging_steps": 100,
  "max_steps": 8244,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4533382224576512e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
